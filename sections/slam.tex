\chapter{Simultaneous Localization and Mapping}
\label{chapter:slam}

\textbf{Author: Lukas Leskovar} 

%frame of reference klingt nicht so gut
The problem of localizing as well as navigating a system through a completely or partly unknown environment without any external coordinate system (i.e. GPS, Optical Beacon Tracking, etc.) has proven itself to be one of the most complex and yet fundamental topic in many scientific research fields with robotics being most prominent. The main approach to this problem is Simultaneous Localization and Mapping (SLAM) which dates back to the mid 1980s. Back then the first solutions based on Extended Kalman Filters or Rao-Blackwellised Filters were formulated. \footcite{durrantSlam2006}  \footcite{cadenaSlamFuture2016}

To date the topic of SLAM has matured, algorithms have gotten more reliable and robust and are utilized in many industries. Applications for SLAM range from Navigating a Mars Rover over autonomous cars or warehouse robots to simple household appliances like vacuum cleaners. 

As one major topic of this thesis is robot navigation in a GPS-denied area as well as mapping of such environment, different modern SLAM approaches and solutions utilized by the project team are discussed in this chapter.

\section{Localization}
State-Estimation aims to reconstruct the state of a system using interoceptive measurements (e.g. acceleration, velocity, etc.) as well as an exteroceptive model (e.g. position and orientation) of the system. \footcite{barfootStateEstimation2017}
Put into the context of mobile robotics this means that in order to perform comprehensive localization of a mobile robot a sensor fusion between on-board sensors and an external coordinate system or map ought to be performed as solely relying on sensory input would result that the  calculated pose of the robot would quickly drift as measurement errors accumulate compared to reality.
%Exemplary for such a robot would be a drone utilizing a Inertial Measurement Units (IMU) odometry as well as GPS positional data to estimate its current position.
Exemplary for such a system would be an industrial robot utilizing a construction plan to correct errors by wheel-encoded odometry as well as to navigate through a factory. 

\section{Mapping}
Contrary to localization and state-estimation, the current pose of the system is known while its environment remains uncharted.
Therefore stand-alone mapping aims to generate a model of its environment by evaluating sensor readings of environmental features as well as the systems pose to reconstruct aforementioned features in a global reference frame. 
Mapping applications often combine technologies typically found in scientific fields such as photogrammetry, computer vision or robotics. 
Another example would be a drone computing camera images and GPS positional data with a photogrammetric algorithm to reconstruct a 3D-Model of a building. 


\section{Performing Localization and Mapping}



\section{Application Scenarios}

\subsection{Map Acquisition}

\subsection{Black-Box Localization}

\subsection{Continuos Map Exploration}


\section{2D SLAM}

\subsection{Evidence Grid-based SLAM}

\subsection{Graph-based SLAM}

\subsection{Feature-based SLAM}


\section{3D SLAM}

\subsection{Visual SLAM}

\subsection{Graph-based SLAM}


\section{Obtaining Odometry}

\subsection{Wheel Encoder Odometry}

\subsection{Visual Odometry}

\subsection{Visual Inertial Odometry}


\section{Loop Closure for Visual SLAM}

\subsection{Appearance-based}

\subsection{Deep Learning}


\section{Map optimization}



\filbreak