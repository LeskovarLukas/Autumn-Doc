\chapter{Simultaneous Localization and Mapping}
\label{chapter:slam}

\textbf{Author: Lukas Leskovar} 

%frame of reference klingt nicht so gut
The problem of localizing as well as navigating a system through a completely or partly unknown environment without any external coordinate system (i.e. GPS, Optical Beacon Tracking, etc.) has proven itself to be one of the most complex and yet fundamental topics in many scientific research fields with robotics being most prominent. The main approach to this problem is Simultaneous Localization and Mapping (SLAM) which dates back to the mid 1980s. Back then the first solutions based on Extended Kalman Filters or Rao-Blackwellised Filters were formulated. \footcite{durrantSlam2006}  \footcite{cadenaSlamFuture2016}

To date the topic of SLAM has matured, algorithms have gotten more reliable and robust and are utilized in many industries. Applications for SLAM range from Navigating a Mars Rover over autonomous cars or warehouse robots to simple household appliances like vacuum cleaners. 

As one major topic of this thesis is robot navigation in a GPS-denied area as well as mapping of such environment, different modern SLAM approaches and solutions utilized by the project team are discussed in this chapter.

\section{Localization}
%state estimation beschreiben dass pose sowie andere informationen wie geschw. usw. erfasst werden. 
Localization or state-Estimation aims to reconstruct the state of a system using interoceptive measurements (e.g. acceleration, velocity, etc.) as well as an exteroceptive model (e.g. position and orientation) of the system. \footcite{barfootStateEstimation2017}
Put into the context of mobile robotics this means that in order to perform comprehensive localization of a mobile robot a sensor fusion between on-board sensors and an external coordinate system or map ought to be performed as solely relying on incremental sensors for odometry would quickly result in large accumulated errors.
%Exemplary for such a robot would be a drone utilizing a Inertial Measurement Units (IMU) odometry as well as GPS positional data to estimate its current position.
Exemplary for such a system would be an industrial robot utilizing a construction plan to correct errors by wheel-encoded odometry as well as to navigate through a factory. 

\section{Mapping}
Contrary to localization and state-estimation, the current pose of the system is known while its environment remains uncharted.
Therefore stand-alone mapping aims to generate a model of its environment by evaluating sensor readings of environmental features as well as the systems pose to reconstruct aforementioned features in a global reference frame. 
Mapping applications often combine technologies typically found in scientific fields such as photogrammetry, computer vision or robotics. 
Another example would be a drone computing camera images and GPS positional data with a photogrammetric algorithm to reconstruct a 3D-Model of a building. 


\section{Localization and Mapping}
The aforementioned technologies are considered rather simplistic problems as either the environments map is given or reliable pose-estimation can be provided. While most applications meet either of these criteria with pre-built maps or GPS being available, in some environments such as indoors, mineshafts or outer space both the systems pose and environment remain uncertain and need to be determined simultaneously hence simultaneous localization and mapping. 
To summarize, the crux of the SLAM problem is that localizations requires a map and mapping depends on pose estimates however neither are certain. 

To approach this problem in a structured way a SLAM system usually comprises two main components:
\begin{itemize}
	\item A front-end in charge of abstracting sensory input to be used in the back-end by performing feature extraction as well as data association. 
	%Furthermore it is responsible for associating corresponding features over multiple measurements, which is typically referred to as short-term data association. Long-term data association or loop closure therefore aims to link current measurements to previously observed features thus  correcting accumulated odometry errors as well as adapting the global topology. 
	\item A back-end performing probabilistic estimation based on the abstracted data fed in by the front-end. The back-end also provides information to the front-end supporting loop closure detection. 
\end{itemize}

The following sections will mainly focus on the SLAM back-end and dissect the problem by reviewing different probabilistic approaches. 


%In order to partially solve this dilemma SLAM incorporates loop closure to correct the global map as well as positional estimates provided by odometry. A loop closure event occurs when revisiting previously mapped landmarks and associating relations between features to adapt the global topology. %Without loop closure a mobile robot would perceive its environment as a infinite corridor.


\section{Data Association}
While many aspects of the front-end remain application specific each SLAM system typically contains modules for data association in the following ways.
Short-term data association or feature tracking is responsible for associating corresponding features over multiple measurements while long-term data association aims to detect and link similarities between current measurements and previously observed features. These loops help correcting accumulated odometry errors as well as optimizing the global topology. 
A loop closure typically event occurs when revisiting previously mapped landmarks.

\section{Map Representation}
The way a robot perceives its environment and maintains a accurate map of its environment is directly dependant on many criteria such as complexity of tasks, size of its environment as well as measurement quality mainly influenced by sensor noise. 
Tailoring to benefit some of the aforementioned criteria most robotic mapping systems utilize either of two paradigms, metric or topological, each proposing their respective strengths and weaknesses.

Metric or grid-based maps build a map of the robots environment as occupancy grids, with each grid cell indicating the presence of an obstacle. The main benefit using metric maps is the facilitated construction of large-scale mappings as well as non-ambiguous determination of places. However such maps have significant drawbacks concerning space as well as time complexity and require accurate pose estimation of the robot.

Topological or feature-based maps reconstruct their environment as graphs with each node representing a feature or landmark perceived by the robots sensors. In contrast to metric maps they allow for comprehensive path planning and are significantly more compact as its resolution is directly proportional to the environments complexity. \footcite{thrunMaps1998}


\section{Probabilistic Definition}
To describe probabilistic SLAM lets assume a robot is moving through an environment observing different landmarks at different times. 
The goal is that, for any time instant $ k $, the robots state vector $ x_{k} $ and time invariant set of all landmark positions $ m $ given the landmark observations $ Z_{0:k}$, controls $ U_{0:k} $ and known initial location $ x_{0} $ are computed.

\begin{equation}\label{fullSLAM}
	P(x_{k:0}, m | Z_{0:k}, U_{0:k}, x_{0})
\end{equation}

In \ref{fullSLAM}, which is often referred to as "Full-SLAM" or "Offline-SLAM", the joint posterior density of the robots trajectory and landmark locations is estimated. In other words, this formulation of the problem aims to recover the whole robot trajectory as well as the map given the observation sets $ Z $ and $ U $. 

\begin{equation}\label{onlineSLAM}
	P(x_{k}, m | Z_{0:k}, U_{0:k}, x_{0})
\end{equation}

The pendant to this is "Online-SLAM" which aims to calculate the whole map but only the robots latest location at time instant $ k $, as seen in \ref{onlineSLAM}. In contrast to "Full-SLAM", performing batch computation on the whole data, algorithms pursuing this approach typically compute the probability distribution incrementally. 

To compute either problem a mathematical model representing the robots state transition and a model describing observations need to be defined:

\begin{equation}\label{motionModel}
	P(x_{k} | x_{k-1}, u_{k})
\end{equation}

\begin{equation}\label{observationModel}
	P(z_{k} | x_{k}, m)
\end{equation}

The motion model \ref{motionModel} describes the robots location at time $ k $ given the known previous location $ x_{k-1} $ and odometry $ u_{k} $ assuming the state-transition is a Markov process \footcite{haeneltMarvoModel2006}.
\ref{observationModel} calculates the probability of observing a landmark $ z_{k} $ when the robots location $ x_{k} $ and environment $ m $ are known.

%The joint posterior is then implemented in a recursive prediction and correction form which is often described as time-update and measurement-update:

For filtering approaches which are discussed later in this chapter, the joint posterior is then implemented in a recursive prediction and correction form which is often described as time-update and measurement-update:

\begin{equation}\label{timeUpdate}
	P(x_{k}, m | Z_{0:k-1}, U_{0:k}, x_{0}) = \int P(x_{k} | x_{k-1}, u_{k}) * P(x_{k-1}, m | Z_{0:k-1}, U_{0:k-1}, x_{0}) dx_{k-1}
\end{equation}


\begin{equation}\label{measurementUpdate}
	P(x_{k}, m | Z_{0:k}, U_{0:k}, x_{0}) = \frac{P(z_{k} | x_{k}, m) * P(x_{k}, m | Z_{0:k-1}, U_{0:k}, x_{0}))}{P(z_{k} | Z_{0:k-1}, U_{0:k})}
\end{equation}

The time update in \ref{timeUpdate} calculates an believe of the robots state using a previously known state at $ k - 1 $ and state-transition given the newest control $ u_{k} $.
In the next, the measurement update \ref{measurementUpdate}, step a observation $z_{k} $ is taken and the previously calculated estimate is corrected using Bayes-Theorem. 

\section{Solution Paradigms} 
Over time many different approaches to the SLAM problem have been developed which can be categorized into either of three paradigms. The two mature ones are based on recursive filtering techniques while the modern graph-based solutions perform non-linear sparse optimization.

\subsection{Extended Kalman Filter}
The Extended Kalman Filter (EKF) is one implementation of a Bayes Filter for non-linear problems and one of the earliest approaches to the SLAM problem. The author recommends thorough knowledge about Bayes Filters\footcite{tipaldiBayes2020}, the vanilla Kalman Filter and the EKF\footcite{tipaldiEKF2020} before reading this section about its application in SLAM. 


\subsection{Particle Filter}

\subsection{Graph-based}


\section{Visual SLAM}


%\section{Application Scenarios}
%
%\subsection{Map Acquisition}
%
%\subsection{Black-Box Localization}
%
%\subsection{Continuos Map Exploration}
%
%
%\section{2D SLAM}
%
%\subsection{Evidence Grid-based SLAM}
%
%\subsection{Graph-based SLAM}
%
%\subsection{Feature-based SLAM}
%
%
%\section{3D SLAM}
%
%\subsection{Visual SLAM}
%
%\subsection{Graph-based SLAM}
%
%
%\section{Obtaining Odometry}
%
%\subsection{Wheel Encoder Odometry}
%
%\subsection{Visual Odometry}
%
%\subsection{Visual Inertial Odometry}


\section{Loop Closure for Visual SLAM}

\subsection{Appearance-based}

\subsection{Deep Learning}


\section{Map optimization}

\subsection{Bundle Adjustment}



\filbreak