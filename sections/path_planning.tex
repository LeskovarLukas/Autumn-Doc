\chapter{Path Planning}
\label{chapter:path_planning}

\textbf{Author: Fabian Kleinrad} 

A crucial part of autonomy in robotics are the means for planning movements in a cooperative manner with the environment. Methods to accomplish this are generally referred to as path planning algorithms. This chapter will focus on exploring different kinds of approaches to path planning and evaluate which approach is most fitting to be used in a real-time, high-dimensional use case present in the autumn project.


\section{Types of Path Planning}

The problem of finding an optimal path between two points is an old one.
The first proposed solution was Dijkstra's algorithm. However, with steadily evolving computer science, the challenges to be mastered by such algorithms got harder and harder. That is the reason why over the last years, the simple principle of the Dijkstra algorithm has branched out, specializing and excelling in specific real-world applications.
\footcite{Pan2020}

\subsection{Sampling-based Algoritms}

In motion planning, sampling-based algorithms can be differentiated from other kinds of approaches by the way they explore their environment. For example, sampling-based algorithms such as the probabilistic road map algorithm or the rapidly exploring random tree use a random point in their reference space and expand in that direction. This random point is considered a sample.

\subsection{Multiple-Query and Single-Query}

The term multiple-query refers, in connection with path planning Algorithms, to the feasibility of deriving a variety of different paths, without the need of rerunning the algorithm. In contrast, single-query algorithms are only able to compute one path at a time.\newline
Use cases for Multiple-Query Algorithms would be unchanging environments. The reason for that, by generating an extensive grid of connections to be able to calculate a multitude of different start/goal combinations, more computational time is needed.\newline
Single-Query approaches focus on performance instead of reuse-ability, making them ideal for dynamic domains. 
\footcite{Bekris2003}
\footcite{stackexchangeMultiSingleQuery2019}

\section{PRM}

Probabilistic RoadMap is a path planning algorithm tailored to multi-query applications. It is considered one of the most influential sampling-based path planning algorithms. 

The algorithm can be broken down into two phases. The first phase, referred to as the pre-processing phase, starts with an empty graph. At first, it samples n random points and adds them to a set of vertices if they are located in space free from obstacles. After constructing a set of n vertices, it attempts connections between a random vertex and its neighbouring nodes in a predefined radius. This connecting of to vertices is realized with a simple straight-line connection. Finally, all collision-free connections between vertices and their respective neighbours are added to a set of edges. This pre-processing phase is a roadmap, with the number of sampled points determining the quality of to be calculated paths. 
\footcite{Karaman2011}

Upon finishing the initial construction phase of a roadmap, like the one depicted in figure \ref{fig:path_planning_prm}, start/goal combinations can be processed. 
The actual pathfinding in the generated graph is handled by other non-sampling-based pathfinding methods such as A*.\newline
With the PRM focusing on a multi-query approach, it is possible to calculate an arbitrary number of different paths without the need to construct a new graph.

\begin{figure}[h]
	\centering
	\includesvg[width=0.7\linewidth]{img/svg/PRMRoadmap}
	\caption{Example of a roadmap in two dimensional space constructed by the PRM algorithm.}
	\label{fig:path_planning_prm}
\end{figure}

\section{RRT Algorithm}

Rapidly exploring random tree is a path planning algorithm that can be categorized as sampling-based and single-query. In the field of sampling-based path-finding algorithms, it is considered the most influential with the PRM. RRT works by constructing a tree of possible trajectories. Therefore it is first required to define an initial vertex, much like a root. After each following iteration, a random sample is taken from the space considered free from obstacles. After generating a random vertex, the nearest neighbouring point in the tree is searched for. The closest node is then used as a pivot point, and a new vertex is constructed a predefined distance away from the nearest node in the direction of the random sample. Thereafter it is attempted to connect the new vertex with the nearest. If this straight-line connection can exit without colliding with obstacles, it is added to the set of edges. This procedure is depicted in Figure \ref{fig:path_planning_rrt}. The algorithm ends when a new node is within the predefined distance from the goal point. 
\footcite{Karaman2011}

The name rapidly exploring random tree stems from the tree-like structure constructed, like the one depicted in Figure \ref{fig:path_planning_rrt} when exploring spaces. This approach to path planning makes it possible to explore rapidly changing environments efficiently.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{img/rrtIteration}
	\caption{Visualization of the first two iterations (a), (b) when an rrt algorithm is exploring a simple 2d space with an obstacle present. D referring to the predefined distance between vertices.\footcite{Zammit2018}}
	\label{fig:path_planning_rrt}
\end{figure}

\section{A* Algorithm}

The A* algorithm is a simplistic and reliable method compared to other path-planning techniques. Therefore it is nowadays prevalently used in a variety of different applications.\footcite{Zammit2018}\newline
It combines heuristic properties with the traditional virtues of Dijkstra's algorithm. Whereas a purely heuristic approach would not guarantee that a path can be found even if a possible solution existed, the A* guarantees that the shortest path is found.\footcite{Sathyaraj2008}
A* works by trying all possible combinations like the Dijkstra algorithm in a grid or graph-based environment. With A* being based on the Dijkstra algorithm, it favours nodes closer to the current position. Additionally, it follows heuristic principles by putting a higher priority on nodes closer to the goal. An example of what an A* search algorithm looks like in a grid-based environment is depicted in Figure \ref{fig:path_planning_Astar}.\footcite{standfordAStarComparison1997}\newline
With these properties, it can be considered an informed Dijkstra search.
  
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{img/AStarExample}
	\caption{A* path finding around a concave obstacle in a grid-based environment.\footcite{standfordAStarComparison1997}}
	\label{fig:path_planning_Astar}
\end{figure}

\section{Evaluation}

This section will cover the reasons behind the selection of the path-planning algorithm used in autumn. Therefore the performance of each algorithm in relation to the environment provided by the project is going to be evaluated. Additionally, the focus is on properties essential for accomplishing the goal set in the autumn project.

\subsection{Autumn Use-case}

There are several criteria to be fulfilled to be considered a working solution for the challenge of path planning faced by Autumn.
To use one of the aforementioned algorithms, they have to be suitable for a real-time, 3-dimensional application, like the one present in the project.
When working with UAVs, an optimal path must be calculated, reliable and possible in the shortest amount of time. 

\subsection{Comparison}

The following comparison will look at the performance of the three different algorithms already mentioned in this chapter. Knowing that the PRM algorithm does not find a path on its own, it is implied from here on out that the PRM works in combination with the A* algorithm and the A* on its own is only applied with grid-based environments.  

\subsubsection{Computational time requirement}

An essential requirement to be fulfilled by the path planning algorithm of the Autumn project is to require as little computational time as possible. Taking a look at the PRM algorithm, with its principle of reusing the generated graph, as a roadmap, resulting in a short runtime of the algorithm, when looking at the computation of multiple paths. The best-case scenario for the PRM in this configuration would be an A* algorithm running in a graph-based environment, with the PRM only having to generate the graph and improve it progressively. A problem that arises is that this best-case scenario is impossible to happen in the Autumn project. Like in Autumn, starting uneducated about the environment is the worst case for the PRM. At first, the PRM algorithm would generate a roadmap in an environment where most of the obstacles are still unknown. After the drone gets its first path to its destination, it detects obstacles and expands the known space for the algorithm. With the environment changing as much as in Autumn, it would be far too expensive to rewire the existing roadmap around new obstacles. A* is the best-case scenario in a graph-based environment for the PRM, but what about now running the A* standalone in a grid-based environment. Grid-based environments tend to be very resource-intensive, with full coverage of the entire space. To preclude the possibility of large portions of the search being dissipated, the A* is biased towards the goal. When comparing the A* to the PRM in terms of computational speed in Autumn, A* would be superior because of the substantial amount of time the PRM takes to generate a roadmap, only to discard it a few iterations later. That being said, the A* still needs to cover a vast grid, depending on the granularity of the grid. With this, both the A* and PRM algorithms are not the most efficient in the matter of short runtime. RRT follows a graph-based and sampling-based approach like the PRM. It covers the space to be explored within a short time frame. The RRT, in contrast to the PRM, does not take time to construct the graph and then start its pathfinding. RRT searches for a path while constructing the tree-like structure. This results in the fastest computational time of all other mentioned algorithms when looking at one-time path planning. With the reference space of the algorithm in Autumn being drastically and continuously changing, it resembles a one-time use path perfectly fitted to be determined by a single-query path planning algorithm like the RRT.

\subsubsection{Scalability for high-dimensional spaces}

Thus far, the application of proposed algorithms happened in a two-dimensional environment. However, when working with UAVs, there is the added challenge of a third dimension to be covered, in contrast to using ground-based vehicles. This added dimension imposes new challenges that the whole system must handle, with the means to plan a path being one of the most affected.
Additional time complexity being the most crucial change when working in a higher dimension, it is essential to be as efficient as possible. The last point covered the time required for each algorithm. With most path-planning algorithms having a time complexity of \(O\left(b^d\right)\)\footcite{stackexchangeAstarTimeComplexity2019}. With A* being one of the most time-intensive.
In this equation, the variable $b$ is the branching factor and describes the number of descendants of a parent node. $d$ refers to the depth of the goal node. The worst-case scenario would be \(O\left(|V|\right)\), meaning that every vertex of the reference space has to be checked. The problem of three dimensions is that the added dimension exponentially increases the number of vertices. A* being a simple approach with brute force characteristics is not suitable for application in high dimensional spaces. 

Comparing the RRT to the A* highlights the benefits of a sampling-based approach. While the A* looks at direct neighbours to continue the search, RRT has a step range as a predefined constant. Therefore the RRT explores faster due to a rougher coverage of the space. This means in relation to higher-dimensional spaces, it converges more efficiently than the A*.

\subsection{Conclusion}

The RRT came out on top by evaluating the potential algorithms to be used in the autumn project. With each algorithm providing unique features best fitted for the use-case they are designed for, the problems the RRT algorithm tries to solve are the same encountered in autumn. Properties like space complexity and path quality were neglected in this comparison due to the low importance of the project. By shifting the computation away from the drone, the importance of minimum time far outweighs the required space. Furthermore, the need for an optimal path is not required on account of the goal being to cover the whole space eventually. That being said, a significant drawback of the base RRT algorithm is the incapability to provide the possibility to improve on an existing path by rewiring the graph. A variant of RRT, the RRT* solves this exact problem.


\section{RRT* Algorithm}

This section will cover the improved version of the RRT algorithm mentioned above. The RRT* algorithm is used in the Autumn project as the path planning algorithm. The rationale for this decision is covered in the evaluation section. 

\subsection{Concept behind RRT*}

A problem that arises when using the RRT algorithm is that finding an optimal path is impossible due to the lack of rewiring options. Therefore the RRT* algorithm was invented. 
The improved algorithm works differently when connecting a newly sampled node into the existing tree structure, which in the RRT is done by connecting the new node to its nearest neighbour. In the case of the RRT*, it calculates the cost of other possible connections stemming from the root node. Thereby a set of nodes closest to the newly sampled vertex are used as possible connection candidates. Rewiring the tree after each new node is sampled makes it possible for a near-optimal path to be found.

\subsection{Algorithm}

The RRT* works at first the same as the RRT algorithm. It first defines a set of vertices, $V$ with the start node and an empty set of Edges, $E$. In contrast to the RRT algorithm is, the runtime of the RRT* algorithm is not dependent on how fast the goal node is reached but instead on the degree of optimization for the calculated path.
Line four to six in Algorithm 1 are the same as the base algorithm. Thereby is a random node sampled, the nearest node in relation to the random node is calculated, and a new node is generated. After checking if a straight-line connection is possible between $x_{nearest}$ and $x_{new}$, a set of neighbouring vertices, $X_{near}$ is initialized.
$X_{near}$ consist of nodes in the tree with a distance $D$, in relation to $x_{new}$. Thereafter $x_{new}$ gets added to the $V$. In lines 9 to 13, the cost of paths connecting the nodes of $X_{near}$ with $x_{new}$ get calculated, and an edge between the node with the cheapest path, $x_{min}$ and $x_{new}$ gets added to $E$. The final stage of the RRT* is to rewire all neighbouring nodes in $X_{near}$ if the path connecting to $x_{new}$ is cheaper than the original path to the root vertex. 

\begin{algorithm}[H]
	\caption{RRT* 2011\footcite{Karaman2011}}
	\SetKwFunction{FObstacleFree}{ObstacleFree}
	\SetKwFunction{FSampleFree}{SampleFree}
	\SetKwFunction{FNearest}{Nearest}
	\SetKwFunction{FNear}{Near}
	\SetKwFunction{FCost}{Cost}
	\SetKwFunction{FCollisionFree}{CollisionFree}
	\SetKwFunction{FSteer}{Steer}
	\SetKwFunction{FLine}{Line}
	$V \gets \{x_{init}\}$\;
	$E \gets 0$\;
	\For{$i \gets 1$ \textbf{to} $n$} {
		$x_{rand} \gets \FSampleFree()$\;
		$x_{nearest} \gets \FNearest(G = (V, E), x_{rand})$\;
		$x_{new} \gets \FSteer(x_{nearest}, x_{rand}, D)$\;
		\If{\FObstacleFree($x_{nearest}$, $x_{new}$)}{
			$X_{near} \gets \FNear(G = (V, E), x_{new}, D)$\;
			$V \gets V \cup \{x_{new}\}$\;
			$x_{min} \gets x_{nearest}$\;
			$c_{min} \gets \FCost(x_{nearest}) + c(\FLine(x_{nearest}, x_{new}))$\;
			\ForEach{$x_{near} \in X_{near}$} {
				\If{\FCollisionFree($x_{near}$, $x_{new}$) $\land$ \FCost($x_{near}$) + $c(\FLine(x_{near}, x_{new})) < c_{min}$}{
					$x_{min} \gets x_{near}$\;
					$c_{min} \gets \FCost(x_{near}) + c(\FLine(x_{near}, x_{new}))$\;
				}
			}
			$E \gets E \cup \{(x_{min}, x_{new})\}$\;
			\ForEach{$x_{near} \in X_{near}$} {
				\If{\FCollisionFree($x_{near}$, $x_{new}$) $\land$ \FCost($x_{new}$) + $c(\FLine(x_{near}, x_{new})) < c_{near}$}{
					$x_{parent} \gets Parent(x_{near})$\;
				}
				$E \gets (E \backslash \{(x_{parent}, x_{near})\} \cup \{(x_{new}, x_{near})\})$\;
			}
		}
	}
	\Return G = (V, E);
\end{algorithm}

\section{RRT* Variants}

\subsection{RT-RRT*}

The RT-RRT* takes focus on real-time path planning. RT-RRT* makes it possible to reposition the root node. Using this online tree rewiring strategy makes it possible to keep the previously sampled tree.
The two core principles introduced with the RT-RRT*are tree expansion and tree rewiring. 
At first, the Algorithm starts by initializing a root node. After each following iteration, the tree expands and rewires. This sampling lasts for a user-defined time and is followed by planning a path from the root. The user controls the length of this path by defining the number of steps the path consists of. In this phase, the agent is moved gradually towards the tree root. Thereafter, when path planning is finished, and the agent is located at the position of the tree root, the position of the root is changed to the next node in the generated path. This approach enables the agent to move without the time needed to compute the whole path.
Expansion in the RT-RRT* is done similar to the base algorithm by sampling a random node, finding its neighbour with the minimum cost-to-reach and connecting them.
The rewiring is done in the default scenario because newly added nodes have a smaller cost-to-reach than the parent of a specific node. However, rewiring is needed if the environment changes in the second case. Therefore a more significant portion of the tree has to change. Thereby two different modes are utilized. The first one consists of rewiring the tree in a circle centred around the tree node. For the second option, both focused and uniform sampling is used, with the difference that it is not done for one node but instead concentrates on patches.
\footcite{Naderi2015}

\subsubsection{RT-RRT* in Autumn}

When applying the concept of the RT-RRT* to Autumn, it would seem a good idea. However, a closer look uncovers that the proposed RT-RRT* only works efficiently in environments with limited changes. Rewiring the tree, done in the case of a dynamic obstacle changing, does not make sense when the obstacle referred to covers a large portion of the space. This is the case in Autumn because contrary to the examples in the paper covering the RT-RRT*, the algorithm is not educated about the environment. Only while moving are obstacles and boundaries discovered. In general, the RT-RRT* uses concepts of road-maps like the one generated in the PRM algorithm and applies it to the RRT* algorithm.  

\subsection{Smart-RRT*}

Smart-RRT* focuses on solving the problem imposed using the RRT* algorithm. However, with the slow convergence rate of the RRT* towards an ideal path, it takes up to an infinite amount of time to reach the most optimal path. Therefore Smart-RRT* utilizes two techniques, path optimization and intelligent sampling, in an effort of accelerating the rate of convergence. 
It works the same as the base algorithm till the first path is found. From there on out, it applies path optimization and intelligent sampling. Path optimization works by interconnecting nodes in the found path that are directly visible. This leads based on triangular inequality to a shorter path. The reconnected nodes are then used as biased points for intelligent sampling. Intelligent sampling samples new points based on a bias generated from finding a shorter path. The result is a greater node density in the critical points on the path, primarily located around obstacles.  
\footcite{Islam2012}

\subsubsection{Smart-RRT* in Autumn}
Using Smart-RRT* improves the convergence rate and time to reach an optimal path drastically. This leaves the question of why not use this improved version of the implemented algorithm in the project. When looking at this, it is vital to keep the goal in mind that the autumn project aims to reach, which is to capture an environment in the form of a 3-dimensional model. Therefore it is unnecessary to compute an optimal path. The whole space will be covered eventually, which would only be a waste of computational power to invest in additional path optimization. 

\section{autumn\_pathplanning\_2d Benchmark}

This section will concern itself with the performance of the autumn\_pathplanning\_2d Algorithm. The main aspects of these tests are reliability, computational time requirement and path length. That are the most significant values in the case of the Autumn use case.

\subsection{Experimental Setup}
The experiment is divided into three different parts. Each of these test scenarios contains data for a range of varying amounts iterations. By the nature of the RRT* algorithm, the number of iterations defines the resulting path's quality. Quality in this context refers to the length of the generated path. The higher the iteration count, the higher the probability of getting a shorter path. These iteration samples range from 1000 to 10000. 

\subsubsection{Test Environments}

The three tests were conducted in two different environments. Test 1 was carried out on Map 1, to be seen in Figure \ref{fig:PrecisionTestMaps}. Defining characteristics of Map 1 are an open environment with minimal obstacles. These open style environments without any borders present a challenge for the algorithm closer described in the Section \ref{sec:PrecisionTestEval}. Tests two and three were performed on Map 2, which can be seen in Figure \ref{fig:PrecisionTestMaps}. Map 2 is a closed environment with higher complexity than Map 1.  

\begin{figure}[h]
	\centering
	\includesvg[width=0.65\linewidth]{img/svg/ppTestMaps}
	\caption{a) showing map 1 for test 1. Map 1 consist of a rectangular obstacle in the centre. b) is displaying map 2 used for test 2 and test 3. It compromises a three path design, which can be seen by three distinct paths to the goal, bottom, top and through the middle.}
	\label{fig:PrecisionTestMaps}
\end{figure}


\subsection{Results}
\label{sec:PrecisionTestResults}
The following will present the results of tests conducted to measure reliability, computational time requirement and path cost.

\subsubsection{Test 1}
\label{sec:test1}
Test 1 was conducted on map 1, with iterations between 1000 and 8000, with an increment of 1000. To minimize the impact of the random nature of the RRT algorithm, every configuration generated 100 paths, and the time and cost present in Table \ref{tab:pp_precision1} is the average of all 100 runs. The same table shows how many of the runs failed, which means they could not get to the goal, and no path was found. Additionally, to demonstrate the data coherence of the individual runs the standard deviation of the measured time as well, as the standard deviation of the path cost is listed.   

\begin{table}[!ht]
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{|l||l|l|l|l|l|l|l|l|}
		\hline
		Iterations & 1000 & 2000 & 3000 & 4000 & 5000 & 6000 & 7000 & 8000 \\ \hline\hline
		Mean time[ms] & 36,61  & 139,92  & 306,20  & 533,78  & 818,56  & 1165,98  & 1563,83  & 2018,33  \\ \hline
		Mean cost & 118,52  & 91,71  & 82,43  & 78,72  & 76,37  & 75,49  & 74,58  & 74,27  \\ \hline
		Failed[\%] & 2  & 0  & 0  & 0  & 0  & 0  & 0  & 0  \\ \hline
		$\sigma$ time[ms] & 3,70  & 10,24  & 17,40  & 24,41  & 30,08  & 40,22  & 47,50  & 51,73  \\ \hline
		$\sigma$ cost & 38,72  & 14,58  & 7,24  & 4,63  & 3,59  & 2,85  & 1,96  & 1,69  \\ \hline
		Min time[ms] & 33,37  & 130,07  & 286,27  & 498,46  & 771,62  & 1101,18  & 1481,98  & 1909,52  \\ \hline
	\end{tabular}
	\label{tab:pp_precision1}
	\caption{Results of test 1 conducted on map1}
\end{table}

\subsubsection{Test 2}
\label{sec:test2}
Test 2 uses the same principle as test 1, while being performed on map 2. Furthermore, test 2 uses a sample size of 500 paths per iteration configuration. Additionally, nodes in test 2 are closer together due to the smaller node spacing parameter. 

\begin{table}[!ht]
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{|l||l|l|l|l|l|l|l|l|}
		\hline
		Iterations & 2000 & 3000 & 4000 & 5000 & 6000 & 7000 & 8000 & 9000 \\ \hline\hline
		Mean time[ms] & 8,36  & 13,66  & 19,54  & 25,36  & 32,31  & 38,73  & 46,33  & 53,84  \\ \hline
		Mean cost & 181,82  & 181,99  & 181,21  & 181,00  & 180,65  & 180,55  & 179,77  & 179,59  \\ \hline
		Failed[\%] & 36  & 25  & 16  & 16  & 12  & 12  & 9  & 8  \\ \hline
		$\sigma$ time[ms] & 4,60  & 6,63  & 7,98  & 10,06  & 11,51  & 14,04  & 14,57  & 16,23  \\ \hline
		$\sigma$ cost & 88,21  & 79,14  & 67,38  & 66,64  & 58,74  & 60,41  & 52,78  & 49,56  \\ \hline
		Min time[ms] & 4,92  & 4,21  & 7,00  & 7,05  & 7,71  & 11,07  & 17,20  & 18,30  \\ \hline
	\end{tabular}
	\label{tab:pp_precision2}
	\caption{Results of test 2 conducted on Map2.}
\end{table}

\subsubsection{Test 3}
\label{sec:test3}
Test 3 works with the same principle as the aforementioned tests. Test 3 was also performed on map 2 and serves as a control run to test the significance of the results of test 2. Test 3 is a replica of test 2.

\begin{table}[!ht]
	\centering
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{|l||l|l|l|l|l|l|l|l|}
		\hline
		Iterations & 2000 & 3000 & 4000 & 5000 & 6000 & 7000 & 8000 & 9000 \\ \hline\hline
		Mean time[ms] & 10,93  & 17,47  & 24,96  & 32,66  & 41,13  & 49,07  & 58,34  & 69,14  \\ \hline
		Mean cost & 181,89  & 182,17  & 181,47  & 181,50  & 181,45  & 180,28  & 180,02  & 180,12  \\ \hline
		Failed[\%] & 39  & 23  & 15  & 11  & 11  & 7  & 9  & 8  \\ \hline
		$\sigma$ time[ms] & 5,97  & 8,06  & 9,56  & 11,30  & 14,17  & 14,49  & 19,15  & 20,57  \\ \hline
		$\sigma$ cost & 89,29  & 77,21  & 64,72  & 57,30  & 58,05  & 47,50  & 52,91  & 50,36  \\ \hline
		Min time[ms] & 4,17  & 5,85  & 10,42  & 14,81  & 9,69  & 12,41  & 13,51  & 15,87  \\ \hline
	\end{tabular}
	\label{tab:pp_precision3}
	\caption{Results of test 3 conducted on Map2.}
\end{table}

\subsection{Evaluation}
\label{sec:PrecisionTestEval}
Comparing the results from Section \ref{sec:PrecisionTestResults}, it is made obvious that test 1 has a much higher time requirement than test 2 and 3. This can be observed in figure \ref{plot:PathPlanning2dPrecTime}. It has do mentioned that this plot uses a logarithmic y-axis. The behaviour can be ascribed to the fundamental difference between map 1 and map 2. Map 2 has borders containing the algorithm, while map 1 does not. The enclosed environments are better suited because if the algorithm encounters an obstacle or, in this case, a wall, it will start to propagate along with it, resulting in fewer nodes being placed in the wrong direction to the goal. 
Another essential fact to take into account is that tests 2, and 3 use a smaller node spacing parameter. By this means, newly generated nodes are closer to their nearest neighbour, which results in less elaborate collision detection. 
An observation made looking at Figure \ref{plot:PathPlanning2dPrecTime}, that was already anticipated, is that with an increasing number of iterations, the time to compute a path also increases. 

\input{sections/plots/PathPlanningPrecTime}

Now looking at Figure \ref{plot:PathPlanning2dPrecCost} the way the cost of generated paths is affected by varying the number of iterations can be observed. Thereby only data from test 2 and 3 are present, due to the fact that test 1 uses a map with a different minimal path length and thus can not be compared with paths from test 2 and 3. The different data points vary strongly, which is primarily due to the fact that the range of iterations is relatively small for this use case. The average time needed to compute a path using 8000 iterations only amounts to 53ms, which is slower than 8ms for 2000 iterations but still quite fast. In order to have more consistency in the decline of the path cost with increasing iterations, a higher iteration count would be needed.

\input{sections/plots/PathPlanningPrecCost}

The last important aspect of this path planning algorithm being its reliability, which can be observed in Figure \ref{plot:PathPlanning2dPrecFailed}. Test 1 being ahead of both test 2 and 3, with a maximum of about 20\% failed. This is due to the fact that test 2, as well as test 3, are performed in a complex environment, were as test 1 was conducted in an environment presenting hardly any challenges. Furthermore, in test 1, the goal is closer than in test 2 and 3. With 1500 iterations, test 1 has a 100\% success rate. What also needs to be taken into account is that tests 2 and 3 are by a multiple faster than test 1. Thereby, it would be no problem to lower the failure rate by increasing the number of iterations while still being faster than the comparable results from test 1.


\input{sections/plots/PathPlanningFailed}
